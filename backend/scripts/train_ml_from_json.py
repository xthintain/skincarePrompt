"""
ä½¿ç”¨products.jsonæ•°æ®è®­ç»ƒMLæ¨èæ¨¡å‹
"""
import json
import pickle
import os
import jieba
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import NearestNeighbors


class SkincareMLRecommender:
    """æŠ¤è‚¤å“æœºå™¨å­¦ä¹ æ¨èç³»ç»Ÿ"""

    def __init__(self):
        self.tfidf_vectorizer = None
        self.tfidf_matrix = None
        self.knn_model = None
        self.products_data = []

    def extract_features_from_name(self, name):
        """ä»å•†å“åç§°ä¸­æå–ç‰¹å¾"""
        features = []

        # 1. æå–å“ç‰Œå…³é”®è¯
        brands = [
            'æ¬§è±é›…', 'è°·é›¨', 'æµ·è“ä¹‹è°œ', 'LA MER', 'å¦®ç»´é›…', 'NIVEA',
            'ç§‘é¢œæ°', "Kiehl's", 'è‡ªç„¶å ‚', 'å…°è”»', 'é›…è¯—å…°é»›', 'èµ„ç”Ÿå ‚',
            'æ¬§è¯—æ¼«', 'ç™¾é›€ç¾š', 'å¤§å®', 'éŸ©æŸ', 'ç€è±é›…', 'è¢‹é¼ å¦ˆå¦ˆ',
            'é’è›™ç‹å­', 'éš†åŠ›å¥‡', 'èœœæ²è†', 'ALORM', 'Losok', 'ORGINESE'
        ]
        for brand in brands:
            if brand in name:
                features.append(f'å“ç‰Œ_{brand}')

        # 2. æå–åŠŸæ•ˆå…³é”®è¯
        effects = [
            'ç¾ç™½', 'ä¿æ¹¿', 'è¡¥æ°´', 'æŠ—çš±', 'ç´§è‡´', 'æ·¡æ–‘', 'ç¥›æ–‘',
            'ä¿®æŠ¤', 'æ»‹æ¶¦', 'æäº®', 'å»é»„', 'æŠ—æ°§åŒ–', 'æ·¡çº¹', 'æ§æ²¹',
            'èˆ’ç¼“', 'ææ‹‰', 'ç„•è‚¤', 'å«©è‚¤', 'å¾¡é¾„', 'æ”¶ç¼©æ¯›å­”', 'æ”¹å–„'
        ]
        for effect in effects:
            if effect in name:
                features.append(f'åŠŸæ•ˆ_{effect}')

        # 3. æå–äº§å“ç±»å‹
        product_types = [
            'é¢éœœ', 'ä¹³æ¶²', 'ç²¾å', 'æ°´ä¹³', 'å¥—è£…', 'ç¤¼ç›’', 'æ´é¢',
            'çˆ½è‚¤æ°´', 'æ™šéœœ', 'æ—¥éœœ', 'çœ¼éœœ', 'æŠ¤æ‰‹éœœ', 'èº«ä½“ä¹³',
            'é¢è†œ', 'ç²¾èƒæ°´', 'å‡éœ²', 'å‡èƒ¶', 'æ´—é¢å¥¶', 'ç²¾åæ¶²'
        ]
        for ptype in product_types:
            if ptype in name:
                features.append(f'ç±»å‹_{ptype}')

        # 4. æå–é€‚ç”¨äººç¾¤
        targets = ['ç”·å£«', 'å¥³', 'å­•å¦‡', 'å„¿ç«¥', 'å®å®', 'å©´å„¿', 'å‡†å­•å¦‡']
        for target in targets:
            if target in name:
                features.append(f'äººç¾¤_{target}')

        # 5. æå–è§„æ ¼ç›¸å…³
        specs = ['å¥—è£…', 'ç¤¼ç›’', 'æ—…è¡Œè£…', 'å°æ ·', 'æ­£è£…']
        for spec in specs:
            if spec in name:
                features.append(f'è§„æ ¼_{spec}')

        # 6. ä½¿ç”¨jiebaåˆ†è¯æå–å…¶ä»–å…³é”®è¯
        words = jieba.cut(name)
        meaningful_words = [w for w in words if len(w) >= 2 and w not in ['çš„', 'å’Œ', 'ä¸', 'æˆ–']]
        features.extend(meaningful_words[:5])

        return ' '.join(features) if features else name

    def load_data_from_json(self, json_path):
        """ä»JSONæ–‡ä»¶åŠ è½½æ•°æ®"""
        print(f"ä» {json_path} åŠ è½½å•†å“æ•°æ®...")

        with open(json_path, 'r', encoding='utf-8') as f:
            products = json.load(f)

        for i, product in enumerate(products):
            # å°†good_rateè½¬æ¢ä¸ºæ¨èç¨‹åº¦ï¼ˆ0-1ä¹‹é—´ï¼‰
            good_rate = float(product.get('good_rate', 0))
            recommendation_score = good_rate / 100.0  # è½¬æ¢ä¸º0-1

            self.products_data.append({
                'åºå·': i + 1,
                'å¹³å°': product.get('source', 'JD'),
                'åç§°': product.get('title', ''),
                'ä»·æ ¼': float(product.get('price', 0)),
                'æ¨èç¨‹åº¦': recommendation_score,
                'ç”¨æˆ·è¯„ä»·æ•°': product.get('comment_num', '0'),
                'ç”¨æˆ·è´­ä¹°æ•°': product.get('comment_num', '0'),  # ä½¿ç”¨è¯„è®ºæ•°ä½œä¸ºè´­ä¹°æ•°
                'sku_id': product.get('sku_id', ''),
                'image_url': product.get('image_url', ''),
                'click_url': product.get('click_url', ''),
                'good_rate': good_rate
            })

        print(f"âœ… æˆåŠŸåŠ è½½ {len(self.products_data)} ä¸ªå•†å“")

    def train_tfidf(self):
        """è®­ç»ƒTF-IDFæ¨¡å‹"""
        print("\nè®­ç»ƒTF-IDFå‘é‡åŒ–æ¨¡å‹...")

        # æå–æ‰€æœ‰å•†å“çš„ç‰¹å¾æ–‡æœ¬
        feature_texts = []
        for product in self.products_data:
            features = self.extract_features_from_name(product['åç§°'])
            feature_texts.append(features)

        # è®­ç»ƒTF-IDFå‘é‡åŒ–å™¨
        self.tfidf_vectorizer = TfidfVectorizer(
            max_features=500,
            min_df=1,
            max_df=0.8,
            ngram_range=(1, 2),
            token_pattern=r'(?u)\b\w+\b'
        )

        self.tfidf_matrix = self.tfidf_vectorizer.fit_transform(feature_texts)
        feature_names = self.tfidf_vectorizer.get_feature_names_out()

        print(f"âœ… TF-IDFçŸ©é˜µå½¢çŠ¶: {self.tfidf_matrix.shape}")
        print(f"   - å•†å“æ•°é‡: {self.tfidf_matrix.shape[0]}")
        print(f"   - ç‰¹å¾ç»´åº¦: {self.tfidf_matrix.shape[1]}")
        print(f"\nğŸ“Š Top 10 é‡è¦ç‰¹å¾:")

        # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„å¹³å‡TF-IDFå€¼
        feature_scores = np.asarray(self.tfidf_matrix.mean(axis=0)).ravel()
        top_indices = feature_scores.argsort()[-10:][::-1]

        for idx in top_indices:
            print(f"   - {feature_names[idx]}: {feature_scores[idx]:.4f}")

    def train_knn(self):
        """è®­ç»ƒK-NNç›¸ä¼¼åº¦æ¨¡å‹"""
        print("\nè®­ç»ƒK-NNç›¸ä¼¼å•†å“æ¨¡å‹...")

        n_neighbors = min(11, len(self.products_data))  # ç¡®ä¿ä¸è¶…è¿‡å•†å“æ€»æ•°

        self.knn_model = NearestNeighbors(
            n_neighbors=n_neighbors,
            metric='cosine',
            algorithm='brute',
            n_jobs=-1
        )

        self.knn_model.fit(self.tfidf_matrix)

        print(f"âœ… K-NNæ¨¡å‹è®­ç»ƒå®Œæˆ")
        print(f"   - ä½¿ç”¨ç®—æ³•: brute force")
        print(f"   - ç›¸ä¼¼åº¦åº¦é‡: cosine")
        print(f"   - é‚»å±…æ•°é‡: {n_neighbors - 1}")

    def save_model(self, model_dir='models/skincare_ml'):
        """ä¿å­˜æ¨¡å‹ï¼ˆç›¸å¯¹äºbackendç›®å½•ï¼‰"""
        print(f"\nä¿å­˜æ¨¡å‹åˆ° {model_dir}...")

        os.makedirs(model_dir, exist_ok=True)

        # ä¿å­˜TF-IDFå‘é‡åŒ–å™¨
        with open(f'{model_dir}/tfidf_vectorizer.pkl', 'wb') as f:
            pickle.dump(self.tfidf_vectorizer, f)

        # ä¿å­˜TF-IDFçŸ©é˜µ
        with open(f'{model_dir}/tfidf_matrix.pkl', 'wb') as f:
            pickle.dump(self.tfidf_matrix, f)

        # ä¿å­˜K-NNæ¨¡å‹
        with open(f'{model_dir}/knn_model.pkl', 'wb') as f:
            pickle.dump(self.knn_model, f)

        # ä¿å­˜å•†å“æ•°æ®
        with open(f'{model_dir}/products_data.pkl', 'wb') as f:
            pickle.dump(self.products_data, f)

        print("âœ… æ¨¡å‹ä¿å­˜æˆåŠŸ")
        print(f"   - tfidf_vectorizer.pkl")
        print(f"   - tfidf_matrix.pkl")
        print(f"   - knn_model.pkl")
        print(f"   - products_data.pkl ({len(self.products_data)} ä¸ªå•†å“)")


def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("æŠ¤è‚¤å“MLæ¨èç³»ç»Ÿè®­ç»ƒï¼ˆåŸºäºproducts.jsonï¼‰")
    print("="*60)

    # åˆ›å»ºæ¨èå™¨
    recommender = SkincareMLRecommender()

    # åŠ è½½æ•°æ®
    json_path = 'data/products.json'
    recommender.load_data_from_json(json_path)

    # è®­ç»ƒTF-IDF
    recommender.train_tfidf()

    # è®­ç»ƒK-NN
    recommender.train_knn()

    # ä¿å­˜æ¨¡å‹
    recommender.save_model()

    print("\n" + "="*60)
    print("âœ… è®­ç»ƒå®Œæˆ!")
    print("="*60)


if __name__ == '__main__':
    main()
